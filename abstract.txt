Despite significant advances in deep learning for face recognition, it remains unclear which human-understandable attributes—such as age, gender, or facial expression—are preserved within deep face representations. This lack of interpretability limits understanding of model biases, robustness, and potential reuse. In this work, we propose a two-stage framework to interpret deep face recognition models by recovering and analyzing facial attributes directly from their learned representations. The first stage extracts facial attributes such as shape, expression, and age, while the second stage examines how these attributes influence recognition decisions. By linking deep representations to identifiable facial traits, the framework provides insights into the decision-making process of face recognition systems, highlights the limitations and boundaries of current models, and guides future improvements. This approach enables a deeper understanding of deep face representations beyond identity recognition, facilitating more transparent, reliable, and interpretable face recognition systems.
